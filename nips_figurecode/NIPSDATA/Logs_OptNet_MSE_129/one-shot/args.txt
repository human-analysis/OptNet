[Arguments]

dataset_root_test = /data/CelebA/
dataset_root_train = /data/CelebA/
dataset_test = CelebA_Privacy
dataset_train = CelebA_Privacy
total_classes = 2
nclasses_a = 2
nclasses_t = 2
input_filename_test = ./data/celeba/celeba-evaluation.csv
input_filename_train = ./data/celeba/celeba-training.csv
adverserial_type = one-shot
model_type_e = preactresnet18
model_type_ea = EA
model_type_et = ET
model_type_a = Adversary
model_type_t = Target
variance = 0.1
model_options_e = {'nfilters': 16, 'r': 129}
model_options_EA = {}
model_options_ET = {}
model_options_A = {}
model_options_T = {}
loss_type_e = Projection_gauss
loss_type_ea = Maxentropy
loss_type_ed = Regression
loss_type_et = Regression
loss_type_a = Regression
loss_type_t = Regression
loss_options_E = {}
loss_options_EA = {}
loss_options_ET = {}
loss_options_ED = {}
loss_options_A = {}
loss_options_T = {}
evaluation_type_ea = Top1Classification
evaluation_type_et = Top1Classification
evaluation_type_a = Top1Classification
evaluation_type_t = Top1Classification
evaluation_options_EA = {}
evaluation_options_ET = {}
evaluation_options_A = {}
evaluation_options_T = {}
resolution_high = 112
resolution_wide = 96
ngpu = 1
batch_size_train = 200
batch_size_test = 250
nepochs_e = 6
nepochs = 7
niters = 7
nthreads = 1
manual_seed = 1
port = 8094
env = main
learning_rate_e = 0.0003
learning_rate_ea = 0.0003
learning_rate_et = 0.0003
learning_rate_a = 0.0003
learning_rate_t = 0.0003
optim_options = {}
optim_options_e = {'weight_decay': 0.0002, 'betas': [0.9, 0.999]}
optim_options_ea = {'weight_decay': 0.0002, 'betas': [0.9, 0.999]}
optim_options_et = {'weight_decay': 0.0002, 'betas': [0.9, 0.999]}
optim_options_t = {'weight_decay': 0.0002, 'betas': [0.9, 0.999]}
optim_options_a = {'weight_decay': 0.0002, 'betas': [0.9, 0.999]}
scheduler_options = {}
scheduler_method_e = MultiStepLR
scheduler_options_e = {'milestones': [5], 'gamma': 0.1}
scheduler_method_ea = MultiStepLR
scheduler_options_ea = {'milestones': [5], 'gamma': 0.1}
scheduler_method_et = MultiStepLR
scheduler_options_et = {'milestones': [5], 'gamma': 0.1}
scheduler_method_t = MultiStepLR
scheduler_options_t = {'milestones': [5], 'gamma': 0.1}
scheduler_method_a = MultiStepLR
scheduler_options_a = {'milestones': [5], 'gamma': 0.1}
log_type = progressbar
same_env = True
r = 129
c = 0.5
d = 5
sigma = 1.0
alpha = [0, 0.1, 0.3, 0.5, 0.7, 0.8, 0.85, 0.9, 0.91, 0.92, 0.93, 0.94]
reg = 0.0001
hdlayers = 8
dataroot = /data/CelebA/
optim_method_e = Adam
optim_method_ea = Adam
optim_method_et = Adam
optim_method_t = Adam
optim_method_a = Adam
device = cuda:0
